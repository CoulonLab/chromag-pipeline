{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - concatenation\n",
    "\n",
    "*The code in this repository is shared under the GPLv3+ license, by Maxime Woringer, Mar. 2021*\n",
    "\n",
    "### input data\n",
    "A Micromanager folder, in which several positions were imaged multiple times, leading to a folder structure as follows:\n",
    "\n",
    "```\n",
    "├── 20200221_release_1\n",
    "│   ├── 20200221_release_1_MMStack_Pos1.ome.tif\n",
    "│   ├── 20200221_release_1_MMStack_Pos2.ome.tif\n",
    "│   ├── 20200221_release_1_MMStack_Pos3.ome.tif\n",
    "│   ├── 20200221_release_1_MMStack_Pos4.ome.tif\n",
    "│   ├── 20200221_release_1_MMStack_Pos5.ome.tif\n",
    "│   └── displaySettings.txt\n",
    "├── 20200221_beforeattr_2\n",
    "│   ├── 20200221_beforeattr_2_MMStack_Pos1.ome.tif\n",
    "│   ├── 20200221_beforeattr_2_MMStack_Pos2.ome.tif\n",
    "│   ├── 20200221_beforeattr_2_MMStack_Pos3.ome.tif\n",
    "│   ├── 20200221_beforeattr_2_MMStack_Pos4.ome.tif\n",
    "│   ├── 20200221_beforeattr_2_MMStack_Pos5.ome.tif\n",
    "│   └── displaySettings.txt\n",
    "├── 20200221_beforeattr_3\n",
    "│   ├── 20200221_beforeattr_3_MMStack_Pos1.ome.tif\n",
    "│   ├── 20200221_beforeattr_3_MMStack_Pos2.ome.tif\n",
    "│   ├── 20200221_beforeattr_3_MMStack_Pos3.ome.tif\n",
    "│   ├── 20200221_beforeattr_3_MMStack_Pos4.ome.tif\n",
    "│   ├── 20200221_beforeattr_3_MMStack_Pos5.ome.tif\n",
    "│   └── displaySettings.txt\n",
    "├── 20200221_beforeattr_4\n",
    "│   ├── 20200221_beforeattr_4_MMStack_Pos1.ome.tif\n",
    "│   └── displaySettings.txt\n",
    "```\n",
    "\n",
    "### output data\n",
    "This scripts creates one movie per position (named with the position number), and recovers the timestamps of the individual frames. The timestamps are exported as a `.xls` file, and overlaid in the concatenated file. \n",
    "Finally, if the timestamp when the magnet was added/removed is present in the configuration (`.cfg`) file, then *(ON|OFF)* flag is present both in the `.xls` file and in the movie overlay.\n",
    "\n",
    "```\n",
    "├── concatenated_Pos1.ome.tif\n",
    "├── concatenated_Pos2.ome.tif\n",
    "├── concatenated_Pos3.ome.tif\n",
    "├── concatenated_Pos4.ome.tif\n",
    "├── concatenated_Pos5.ome.tif\n",
    "├── files_concatenated.txt\n",
    "├── timestamps_Pos1.xls\n",
    "├── timestamps_Pos2.xls\n",
    "├── timestamps_Pos3.xls\n",
    "├── timestamps_Pos4.xls\n",
    "└── timestamps_Pos5.xls\n",
    "```\n",
    "\n",
    "### parameters of this script\n",
    "This script takes very little parameters, they are located in two `.cfg` files in the `config` folder, and in the first cell below.\n",
    "\n",
    "#### `datasets.cfg`\n",
    "\n",
    "Datasets are represented as sections ; sections are delimited by headers [section_name]. Each section should contain:\n",
    "- A `lfn` variable, should be a Python list that contains the list of folders to include for the concatenation. This allows including/excluding folders that should/should not be concatenated\n",
    "- A `forceOn` variable, a list of list, each inner list should contain the timestamp when the magnet was added, the removed. The list can contain multiple lists if the magnet was added/removed several time.\n",
    "  - Example 1: magnet added at 16:00:00, removed at 16:30:00: `forceOn = [['2020-02-21 16:00:00', '2020-02-21 16:30:00']]`\n",
    "  -  Example 2: in addition the magnet was re-added at 17:00 and re-removed at 17:30: `forceOn = [['2020-02-21 16:00:00', '2020-02-21 16:30:00'], ['2020-02-21 17:00:00', '2020-02-21 17:30:00']]`\n",
    "- A `directory` variable, not used in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with the version v1.5.0 (commit e8b5cee), last updated on Mon Mar 22 16:29:51 2021 +0100\n"
     ]
    }
   ],
   "source": [
    "## Imports // DO NOT EDIT\n",
    "running_in_jupyter = True\n",
    "\n",
    "#%matplotlib inline\n",
    "import os, subprocess, shutil, configparser, datetime, sys, ast\n",
    "import importlib #debug, allows to reload a module\n",
    "import chromag_helper as chromag\n",
    "\n",
    "__version__ = \"v1.5.0\"\n",
    "\n",
    "if not chromag.has_screen():\n",
    "    print(\"WARNING, this script works only if a display is connected to the session,\\\n",
    "    or if the session is open using `ssh -X` (display forwarding)\")\n",
    "print(\"Working with the version {} (commit {}), last updated on {}\".format(__version__, str(chromag.get_git_revision_short_hash()), chromag.get_git_revision_date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following datasets are available:\n",
      " 0: 20200221: \t data/Maxime/concatenation/Antoine/20200221/\n",
      " 1: Array7: \t data/Maxime/concatenation/Veer/20191223 - array7/\n",
      " 2: PFS2: \t data/Maxime/concatenation/Veer/20191217 - PFS2/\n",
      "The following dataset has been selected: 20200221\n",
      "\n",
      "Available positions/sequence\n",
      "                                                   0  1  2  3  4  5  \\\n",
      "Sequence                                                              \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...    *  *  *  *  *   \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...    *  *  *  *  *   \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...    *  *  *  *  *   \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...    *               \n",
      "\n",
      "                                                                                            SequenceS  \n",
      "Sequence                                                                                               \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...  20200221_U2OS_stTetR-mCherry_GFP-ferritin_attr...  \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...  20200221_U2OS_stTetR-mCherry_GFP-ferritin_befo...  \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...  20200221_U2OS_stTetR-mCherry_GFP-ferritin_befo...  \n",
      "Antoine/20200221/20200221_U2OS_stTetR-mCherry_G...  20200221_U2OS_stTetR-mCherry_GFP-ferritin_befo...  \n",
      "\n",
      "Available analyses: 20210318, 20200318\n",
      "Using folder: 20210318\n",
      "Found 16 files across 5 positions\n",
      "/data2/Dropbox/CoulonLab/data/Maxime/concatenation/Antoine/20200221/20210318\n"
     ]
    }
   ],
   "source": [
    "## ========      ===========\n",
    "## Selection of the config file\n",
    "## ========      ===========\n",
    "## All the configuration is now in the CFG files. Here, only edit the selected folder if needed\n",
    "## You can edit this if you want, overriden if running outside IPython // \n",
    "# Current options (also listed below): Array7, PFS2, 20200221\n",
    "\n",
    "dataset_to_run = \"20200221\"\n",
    "\n",
    "## ==== DO NOT EDIT ==\n",
    "\n",
    "## Load config files\n",
    "config_datasets_path = \"config/datasets.cfg\"\n",
    "config_main_path = \"config/config.cfg\"\n",
    "assert os.path.isfile(config_datasets_path) and os.path.isfile(config_main_path)\n",
    "\n",
    "cfg_data = configparser.ConfigParser(inline_comment_prefixes=(\"#\",))\n",
    "cfg_data.read(config_datasets_path)\n",
    "cfg_main = configparser.ConfigParser(inline_comment_prefixes=(\"#\",))\n",
    "cfg_main.read(config_main_path)\n",
    "\n",
    "\n",
    "print(\"The following datasets are available:\")\n",
    "for i,s in enumerate(cfg_data.sections()):\n",
    "    print(\" {}: {}: \\t {}\".format(i,s,cfg_data[s][\"directory\"].replace('drift-correction', 'concatenation')[1:-1]))\n",
    "    \n",
    "if running_in_jupyter: ## Select dataset\n",
    "    pass\n",
    "elif not running_in_jupyter and \"--dataset-to-process\" in sys.argv:\n",
    "    print(\"(reading from command-line)\")\n",
    "    dataset_to_run = sys.argv[sys.argv.index(\"--dataset-to-process\")+1]\n",
    "else:\n",
    "    dataset_to_run = cfg_main.get_string(\"Main\", \"dataset_to_process\")\n",
    "assert dataset_to_run in cfg_data.sections(), \"Unrecognized dataset selected: {}, should be one of: {}\".format(dataset_to_run, cfg_data.sections()) \n",
    "print(\"The following dataset has been selected: {}\\n\".format(dataset_to_run))\n",
    "\n",
    "system = cfg_main[\"Main\"][\"system\"][1:-1]\n",
    "use_analysis = cfg_data[dataset_to_run][\"use_analysis\"][1:-1] # trim delimiter\n",
    "\n",
    "lfn = ast.literal_eval(cfg_data[dataset_to_run][\"lfn\"])\n",
    "forceOn = ast.literal_eval(cfg_data[dataset_to_run][\"forceOn\"])\n",
    "\n",
    "## Previous analysis are saved in the file `concatenate_archive.py`\n",
    "## === Do not edit\n",
    "prefix_dict = ast.literal_eval(cfg_main['Main']['prefix_dict'])\n",
    "fiji_dict = ast.literal_eval(cfg_main['Main']['fiji_dict'])\n",
    "lfn = [i if i.endswith(\"/\") else i+'/'  for i in lfn]\n",
    "prefix = prefix_dict[system]\n",
    "fiji_path = fiji_dict[system]\n",
    "prefix_path = os.path.join(prefix, \"data/\") # Dropbox path\n",
    "project_path = os.path.join(prefix, \"projects/chromag\") # chromag's path path\n",
    "CCresult_path = os.path.join(prefix, \"data/Maxime/concatenation/\") # Path to store concatenated files\n",
    "DCresult_path = os.path.join(prefix, \"data/Maxime/drift-correction/\") # Path to store the drift-corrected files\n",
    "\n",
    "# check that files are present\n",
    "assert all([os.path.isdir(chromag.convert_path(os.path.join(prefix_path, i), system)) for i in lfn]), \"ERROR: some files were not found.\"\n",
    "assert os.path.isfile(fiji_path), \"ERROR: fiji not found\"\n",
    "\n",
    "# Handle date manipulations\n",
    "forceLast = \"2029-12-03 17:10:13\"\n",
    "\n",
    "# Sanity checks\n",
    "if len(forceOn)==1 and len(forceOn[0])==1: # Make sure we have a start-stop format\n",
    "    forceOn[0].append(forceLast)\n",
    "assert all([len(i)==2 for i in forceOn]), \"The timestamps should have the shape (t_start, t_stop)\"\n",
    "\n",
    "# Parse dates\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "forceOnP = [[datetime.datetime.strptime(i[0], fmt), datetime.datetime.strptime(i[1], fmt)] for i in forceOn]\n",
    "assert all([i[1]>i[0] for i in forceOnP]), \"End time should be after start time\"\n",
    "assert all([forceOnP[i[1]]<forceOnP[i[0]] for i in range(len(forceOnP)-1)]), \"Not all intersections are disjunct\"\n",
    "\n",
    "## First, we will list the input files, output folders, etc.\n",
    "posidict, fn = chromag.list_files_positions(prefix_path, CCresult_path, use_analysis, lfn)\n",
    "print(fn)\n",
    "\n",
    "## Log (versions, etc)\n",
    "with open(os.path.join(fn, \"pipeline_version.txt\"), 'a') as f: ## Export pipeline version\n",
    "    f.write(\"{}: Working with the version {} (commit {}), last updated on {}\".format(datetime.datetime.now(), __version__, str(chromag.get_git_revision_short_hash()), chromag.get_git_revision_date()))\n",
    "\n",
    "with open(os.path.join(fn, \"concatenation.txt\"), 'a') as f: ## Export concatenation instruction\n",
    "    f.write(\"files:\\n\")\n",
    "    for i in lfn:\n",
    "        f.write(i+\"\\n\")\n",
    "    f.write(str(lfn))\n",
    "    f.write(\"\\nTimestamps:\\n\")\n",
    "    f.write(str(forceOn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Effectively concatenating files [independent block 1]\n",
    "Because file concatenation seems to be a mess, we decide to rely on Fiji to perform this step.\n",
    "\n",
    "This step uses `concat.py`, a Fiji macro. /!\\ Make sure you do not delete them/edit it without care :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Concatenating position 1/5\n",
      "Concatenating position 2/5\n",
      "Concatenating position 3/5\n",
      "Concatenating position 4/5\n",
      "Concatenating position 5/5\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## Running the concatenation\n",
    "## Be careful that imageJ-scifio might not read the overlay properly :s\n",
    "## note that useful debug information will be displayed in the console\n",
    "\n",
    "assert os.path.isdir(fn), \"ERROR: output folder {} does not exists\".format(fn)\n",
    "assert chromag.has_screen(), \"No display found, are you connected using `ssh -X`?\"\n",
    "ddf = chromag.save_timestamps(prefix_path, fn, posidict, system, fieldOn=forceOnP) ## Extract .xls spreadsheets with timestamps\n",
    "\n",
    "tf = \"timestamps.tmp\"\n",
    "onoff = {True: 'ON', False: 'OFF'}\n",
    "for (kk,vv) in posidict.items():\n",
    "    vv  = ddf[kk].path.drop_duplicates().values\n",
    "    with open(tf, \"w\") as f:\n",
    "        [f.write(i+\"\\n\") for i in [\"{:.0f}s ({})\".format(i, onoff[ii]) for (i,ii) in zip(ddf[kk].time_since_beginning.values,ddf[kk].forceActivated.values)]]\n",
    "    out_file = os.path.join(fn, 'concatenated_Pos{}.ome.tif'.format(kk))\n",
    "    shutil.copyfile(tf, out_file+'.time')\n",
    "    if len(vv)<=1:\n",
    "        print(\"Copying position {}\".format(kk))\n",
    "        shutil.copyfile(os.path.join(prefix_path, vv[0]), out_file)\n",
    "        continue\n",
    "    print(\"Concatenating position {}/{}\".format(kk, max(posidict.keys())))\n",
    "    if not os.path.isfile(out_file):\n",
    "        r = subprocess.call([fiji_path, \"concat.py\"]+[os.path.join(prefix_path, i) for i in vv]+[out_file, tf])\n",
    "    assert os.path.isfile(out_file), \"ERROR: output file was not created\"\n",
    "print(\"Done!\")\n",
    "\n",
    "## /!\\ Emergency concat\n",
    "emergency = False\n",
    "if emergency:\n",
    "    for np in [6,10,11,15,17,18,19]: # Positions to concatenate\n",
    "        p = [\"/home/umr3664/CoulonLab/CoulonLab Dropbox/data/Maxime/concatenation/Veer/20191114 - fixed/20191126-before/concatenated_Pos{}.ome.tif\",\n",
    "             \"/home/umr3664/CoulonLab/CoulonLab Dropbox/data/Maxime/concatenation/Veer/20191114 - fixed/20191114_U2OS_stTetR-mCherry_GFP-ferritin_attraction_4bis/20191114_U2OS_stTetR-mCherry_GFP-ferritin_attraction_4_MMStack_Pos{}.ome.tif\",\n",
    "             \"/home/umr3664/CoulonLab/CoulonLab Dropbox/data/Maxime/concatenation/Veer/20191114 - fixed/20191126-after/concatenated_Pos{}.ome.tif\"]\n",
    "        out_file = \"/home/umr3664/CoulonLab/CoulonLab Dropbox/data/Maxime/concatenation/Veer/20191114 - fixed/20191126-final/concatenated_Pos{}.ome.tif\".format(np)\n",
    "        r = subprocess.call([fiji_path, \"concat.py\"]+[os.path.join(prefix_path, i.format(np)) for i in p]+[out_file, tf])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
